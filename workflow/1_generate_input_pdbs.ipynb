{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Receptor: Create df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/nusin/miniconda3/envs/vscode_env/lib/python3.10/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nusin/miniconda3/envs/vscode_env/lib/python3.10/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nusin/miniconda3/envs/vscode_env/lib/python3.10/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nusin/miniconda3/envs/vscode_env/lib/python3.10/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nusin/miniconda3/envs/vscode_env/lib/python3.10/site-packages (from requests) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Error 204: \n",
      "   Gene Symbol  Ensembl Gene ID   Accession Pfam IDs        Identifier  \\\n",
      "0        HMOX1  ENSG00000100292      P09601  Pf01126              1N3U   \n",
      "1        HMOX1  ENSG00000100292      P09601  Pf01126              1N45   \n",
      "2        HMOX1  ENSG00000100292      P09601  Pf01126              1NI6   \n",
      "3        HMOX1  ENSG00000100292      P09601  Pf01126              1OYK   \n",
      "4        HMOX1  ENSG00000100292      P09601  Pf01126              1OYL   \n",
      "5        HMOX1  ENSG00000100292      P09601  Pf01126              1OZE   \n",
      "6        HMOX1  ENSG00000100292      P09601  Pf01126              1OZL   \n",
      "7        HMOX1  ENSG00000100292      P09601  Pf01126              1OZR   \n",
      "8        HMOX1  ENSG00000100292      P09601  Pf01126              1OZW   \n",
      "9        HMOX1  ENSG00000100292      P09601  Pf01126              1S13   \n",
      "10       HMOX1  ENSG00000100292      P09601  Pf01126              1S8C   \n",
      "11       HMOX1  ENSG00000100292      P09601  Pf01126              1T5P   \n",
      "12       HMOX1  ENSG00000100292      P09601  Pf01126              1TWN   \n",
      "13       HMOX1  ENSG00000100292      P09601  Pf01126              1TWR   \n",
      "14       HMOX1  ENSG00000100292      P09601  Pf01126              1XJZ   \n",
      "15       HMOX1  ENSG00000100292      P09601  Pf01126              1XK0   \n",
      "16       HMOX1  ENSG00000100292      P09601  Pf01126              1XK1   \n",
      "17       HMOX1  ENSG00000100292      P09601  Pf01126              1XK2   \n",
      "18       HMOX1  ENSG00000100292      P09601  Pf01126              1XK3   \n",
      "19       HMOX1  ENSG00000100292      P09601  Pf01126              3CZY   \n",
      "20       HMOX1  ENSG00000100292      P09601  Pf01126              3HOK   \n",
      "21       HMOX1  ENSG00000100292      P09601  Pf01126              3K4F   \n",
      "22       HMOX1  ENSG00000100292      P09601  Pf01126              3TGM   \n",
      "23       HMOX1  ENSG00000100292      P09601  Pf01126              4WD4   \n",
      "24       HMOX1  ENSG00000100292      P09601  Pf01126              5BTQ   \n",
      "25       HMOX1  ENSG00000100292      P09601  Pf01126              6EHA   \n",
      "26       HMOX1  ENSG00000100292      P09601  Pf01126      AF-P09601-F1   \n",
      "27       Gene2   ENSG000002XXXX  A0A7I2V3I1  PfXXXXX  AF-A0A7I2V3I1-F1   \n",
      "\n",
      "       Method Resolution    Chain Positions  \n",
      "0       X-ray     2.58 Å      A/B     1-233  \n",
      "1       X-ray      1.5 Å      A/B     1-233  \n",
      "2       X-ray      2.1 Å  A/B/C/D     1-224  \n",
      "3       X-ray     2.59 Å      A/B     1-233  \n",
      "4       X-ray     1.59 Å      A/B     1-233  \n",
      "5       X-ray     2.19 Å      A/B     1-233  \n",
      "6       X-ray     1.58 Å      A/B     1-233  \n",
      "7       X-ray     1.74 Å      A/B     1-233  \n",
      "8       X-ray     1.55 Å      A/B     1-233  \n",
      "9       X-ray     2.29 Å      A/B     1-233  \n",
      "10      X-ray     2.19 Å  A/B/C/D     1-233  \n",
      "11      X-ray     2.11 Å      A/B     1-233  \n",
      "12      X-ray      2.2 Å      A/B     1-233  \n",
      "13      X-ray      2.1 Å      A/B     1-233  \n",
      "14      X-ray     1.88 Å      A/B     1-233  \n",
      "15      X-ray     2.18 Å      A/B     1-233  \n",
      "16      X-ray     2.08 Å      A/B     1-233  \n",
      "17      X-ray      2.2 Å      A/B     1-233  \n",
      "18      X-ray     2.08 Å      A/B     1-233  \n",
      "19      X-ray     1.54 Å      A/B     1-233  \n",
      "20      X-ray     2.19 Å      A/B     1-233  \n",
      "21      X-ray     2.17 Å      A/B     1-233  \n",
      "22      X-ray     2.85 Å      A/B     1-233  \n",
      "23      X-ray     2.95 Å  A/B/C/D     1-292  \n",
      "24      X-ray     2.08 Å      A/B     1-237  \n",
      "25      X-ray      2.0 Å      A/B     1-288  \n",
      "26  Predicted                                \n",
      "27  Predicted                                \n"
     ]
    }
   ],
   "source": [
    "%pip install requests\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Define the two UniProt accession codes\n",
    "uniprot_accessions = [\"P09601\", \"A0A7I2V3I1\"]\n",
    "\n",
    "# Dictionary holding additional info for each accession (adjust as needed)\n",
    "info_dict = {\n",
    "    \"P09601\": {\n",
    "        \"Gene Symbol\": \"HMOX1\",\n",
    "        \"Ensembl Gene ID\": \"ENSG00000100292\",\n",
    "        \"Pfam IDs\": \"Pf01126\"\n",
    "    },\n",
    "    \"A0A7I2V3I1\": {\n",
    "        \"Gene Symbol\": \"Gene2\",         # Replace with correct gene symbol\n",
    "        \"Ensembl Gene ID\": \"ENSG000002XXXX\",  # Replace with correct Ensembl ID\n",
    "        \"Pfam IDs\": \"PfXXXXX\"           # Replace with correct Pfam ID(s)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Prepare the DataFrame with the required columns\n",
    "columns = [\"Gene Symbol\", \"Ensembl Gene ID\", \"Accession\", \"Pfam IDs\",\n",
    "           \"Identifier\", \"Method\", \"Resolution\", \"Chain\", \"Positions\"]\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Loop over each accession\n",
    "for uniprot_accession in uniprot_accessions:\n",
    "    # Build the JSON query to get PDB IDs for experimental structures\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"type\": \"group\",\n",
    "            \"logical_operator\": \"and\",\n",
    "            \"nodes\": [\n",
    "                {\n",
    "                    \"type\": \"terminal\",\n",
    "                    \"service\": \"text\",\n",
    "                    \"parameters\": {\n",
    "                        \"attribute\": \"rcsb_polymer_entity_container_identifiers.reference_sequence_identifiers.database_accession\",\n",
    "                        \"operator\": \"exact_match\",\n",
    "                        \"value\": uniprot_accession\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"terminal\",\n",
    "                    \"service\": \"text\",\n",
    "                    \"parameters\": {\n",
    "                        \"attribute\": \"rcsb_polymer_entity_container_identifiers.reference_sequence_identifiers.database_name\",\n",
    "                        \"operator\": \"exact_match\",\n",
    "                        \"value\": \"UniProt\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"return_type\": \"entry\",\n",
    "        \"request_options\": {\"return_all_hits\": True}\n",
    "    }\n",
    "    \n",
    "    # URL for the RCSB search API\n",
    "    rcsb_url = \"https://search.rcsb.org/rcsbsearch/v2/query\"\n",
    "    \n",
    "    # Send the POST request\n",
    "    response = requests.post(rcsb_url, json=query)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "        pdb_ids = [entry[\"identifier\"] for entry in results.get(\"result_set\", [])]\n",
    "    \n",
    "        # Process experimental structures for this accession\n",
    "        for pdb_id in pdb_ids:\n",
    "            pdb_url = f\"https://data.rcsb.org/rest/v1/core/entry/{pdb_id}\"\n",
    "            pdb_response = requests.get(pdb_url)\n",
    "    \n",
    "            if pdb_response.status_code == 200:\n",
    "                pdb_data = pdb_response.json()\n",
    "                method = pdb_data.get(\"rcsb_entry_info\", {}).get(\"experimental_method\", \"N/A\")\n",
    "                # Extract resolution using the \"resolution_combined\" field\n",
    "                resolution = pdb_data.get(\"rcsb_entry_info\", {}).get(\"resolution_combined\", [\"N/A\"])[0]\n",
    "                if resolution != \"N/A\":\n",
    "                    resolution = f\"{resolution} Å\"\n",
    "    \n",
    "                polymer_entities = pdb_data.get(\"rcsb_entry_container_identifiers\", {}).get(\"polymer_entity_ids\", [])\n",
    "    \n",
    "                for entity_id in polymer_entities:\n",
    "                    entity_url = f\"https://data.rcsb.org/rest/v1/core/polymer_entity/{pdb_id}/{entity_id}\"\n",
    "                    entity_response = requests.get(entity_url)\n",
    "    \n",
    "                    if entity_response.status_code == 200:\n",
    "                        entity_data = entity_response.json()\n",
    "                        # Concatenate chain IDs with '/'\n",
    "                        chain = \"/\".join(entity_data.get(\"rcsb_polymer_entity_container_identifiers\", {}).get(\"auth_asym_ids\", []))\n",
    "                        # Use the length of the canonical sequence (if available) as a proxy for Positions\n",
    "                        seq = entity_data.get(\"entity_poly\", {}).get(\"pdbx_seq_one_letter_code_can\", \"N/A\")\n",
    "                        positions_range = f\"1-{len(seq)}\" if seq != \"N/A\" else \"N/A\"\n",
    "    \n",
    "                        new_row = pd.DataFrame({\n",
    "                            \"Gene Symbol\": [info_dict[uniprot_accession][\"Gene Symbol\"]],\n",
    "                            \"Ensembl Gene ID\": [info_dict[uniprot_accession][\"Ensembl Gene ID\"]],\n",
    "                            \"Accession\": [uniprot_accession],\n",
    "                            \"Pfam IDs\": [info_dict[uniprot_accession][\"Pfam IDs\"]],\n",
    "                            \"Identifier\": [pdb_id],\n",
    "                            \"Method\": [method],\n",
    "                            \"Resolution\": [resolution],\n",
    "                            \"Chain\": [chain],\n",
    "                            \"Positions\": [positions_range]\n",
    "                        })\n",
    "                        df = pd.concat([df, new_row], ignore_index=True)\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "    \n",
    "    # Now add the AlphaFold predicted structure row for this accession\n",
    "    alphafold_id = f\"AF-{uniprot_accession}-F1\"\n",
    "    alphafold_url = f\"https://alphafold.ebi.ac.uk/files/{alphafold_id}.pdb\"\n",
    "    \n",
    "    # Default details for AlphaFold; adjust if you want to parse the file\n",
    "    alphafold_method = \"Predicted\"\n",
    "    alphafold_resolution = \"\"\n",
    "    alphafold_chain = \"\"\n",
    "    alphafold_positions = \"\"\n",
    "    \n",
    "    # Optionally check if the AlphaFold file is available\n",
    "    af_response = requests.get(alphafold_url)\n",
    "    if af_response.status_code == 200:\n",
    "        # You can add parsing logic here if needed\n",
    "        pass\n",
    "    \n",
    "    new_row_af = pd.DataFrame({\n",
    "        \"Gene Symbol\": [info_dict[uniprot_accession][\"Gene Symbol\"]],\n",
    "        \"Ensembl Gene ID\": [info_dict[uniprot_accession][\"Ensembl Gene ID\"]],\n",
    "        \"Accession\": [uniprot_accession],\n",
    "        \"Pfam IDs\": [info_dict[uniprot_accession][\"Pfam IDs\"]],\n",
    "        \"Identifier\": [alphafold_id],\n",
    "        \"Method\": [alphafold_method],\n",
    "        \"Resolution\": [alphafold_resolution],\n",
    "        \"Chain\": [alphafold_chain],\n",
    "        \"Positions\": [alphafold_positions]\n",
    "    })\n",
    "    df = pd.concat([df, new_row_af], ignore_index=True)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "output_path = \"/Users/nusin/Library/Mobile Documents/com~apple~CloudDocs/Desktop/IOV/3_Projects/PPI/1_Input_Proteins_pdbs/df_receptor_hmox1.csv\"\n",
    "df.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Receptor: Download Structures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded (RCSB): 1N3U.pdb\n",
      "Downloaded (RCSB): 1N45.pdb\n",
      "Downloaded (RCSB): 1NI6.pdb\n",
      "Downloaded (RCSB): 1OYK.pdb\n",
      "Downloaded (RCSB): 1OYL.pdb\n",
      "Downloaded (RCSB): 1OZE.pdb\n",
      "Downloaded (RCSB): 1OZL.pdb\n",
      "Downloaded (RCSB): 1OZR.pdb\n",
      "Downloaded (RCSB): 1OZW.pdb\n",
      "Downloaded (RCSB): 1S13.pdb\n",
      "Downloaded (RCSB): 1S8C.pdb\n",
      "Downloaded (RCSB): 1T5P.pdb\n",
      "Downloaded (RCSB): 1TWN.pdb\n",
      "Downloaded (RCSB): 1TWR.pdb\n",
      "Downloaded (RCSB): 1XJZ.pdb\n",
      "Downloaded (RCSB): 1XK0.pdb\n",
      "Downloaded (RCSB): 1XK1.pdb\n",
      "Downloaded (RCSB): 1XK2.pdb\n",
      "Downloaded (RCSB): 1XK3.pdb\n",
      "Downloaded (RCSB): 3CZY.pdb\n",
      "Downloaded (RCSB): 3HOK.pdb\n",
      "Downloaded (RCSB): 3K4F.pdb\n",
      "Downloaded (RCSB): 3TGM.pdb\n",
      "Downloaded (RCSB): 4WD4.pdb\n",
      "Downloaded (RCSB): 5BTQ.pdb\n",
      "Downloaded (RCSB): 6EHA.pdb\n",
      "Downloaded (AlphaFold): AF-P09601-F1.pdb\n",
      "Downloaded (AlphaFold): AF-A0A7I2V3I1-F1.pdb\n"
     ]
    }
   ],
   "source": [
    "%pip install requests\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------\n",
    "# Downloading Experimental (RCSB) PDB Files\n",
    "# ---------------------------\n",
    "\n",
    "# Directory to save the experimental RCSB PDB files\n",
    "rcsb_output_dir = '/Users/nusin/Library/Mobile Documents/com~apple~CloudDocs/Desktop/IOV/3_Projects/PPI/1_Input_Proteins_pdbs/receptor_pdbs/rcsb'\n",
    "os.makedirs(rcsb_output_dir, exist_ok=True)\n",
    "\n",
    "# Base URL for RCSB PDB files\n",
    "rcsb_download_base_url = \"https://files.rcsb.org/download/\"\n",
    "\n",
    "# Function to download experimental PDB files from RCSB\n",
    "def download_rcsb_pdb(identifier, output_directory):\n",
    "    pdb_url = f\"{rcsb_download_base_url}{identifier}.pdb\"\n",
    "    try:\n",
    "        response = requests.get(pdb_url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        pdb_file_path = os.path.join(output_directory, f\"{identifier}.pdb\")\n",
    "        with open(pdb_file_path, 'wb') as pdb_file:\n",
    "            pdb_file.write(response.content)\n",
    "\n",
    "        print(f\"Downloaded (RCSB): {identifier}.pdb\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download {identifier} from RCSB: {e}\")\n",
    "\n",
    "# Load DataFrame (note: using the CSV name from your first chunk)\n",
    "file_path = '/Users/nusin/Library/Mobile Documents/com~apple~CloudDocs/Desktop/IOV/3_Projects/PPI/1_Input_Proteins_pdbs/df_receptor_hmox1.csv'\n",
    "df_receptor_hmox1 = pd.read_csv(file_path)\n",
    "\n",
    "# Create list of PDB IDs (excluding AlphaFold entries)\n",
    "pdb_ids = df_receptor_hmox1['Identifier'][~df_receptor_hmox1['Identifier'].str.startswith(\"AF-\")].tolist()\n",
    "\n",
    "# Download experimental RCSB PDB files\n",
    "for pdb_id in pdb_ids:\n",
    "    download_rcsb_pdb(pdb_id, rcsb_output_dir)\n",
    "\n",
    "# ---------------------------\n",
    "# Downloading AlphaFold PDB Files\n",
    "# ---------------------------\n",
    "\n",
    "# Directory for AlphaFold PDB files\n",
    "alphafold_output_dir = '/Users/nusin/Library/Mobile Documents/com~apple~CloudDocs/Desktop/IOV/3_Projects/PPI/1_Input_Proteins_pdbs/receptor_pdbs/alphafold'\n",
    "os.makedirs(alphafold_output_dir, exist_ok=True)\n",
    "\n",
    "# Base URL for AlphaFold files\n",
    "alphafold_download_base_url = \"https://alphafold.ebi.ac.uk/files/\"\n",
    "\n",
    "# Function to download AlphaFold PDB files\n",
    "def download_alphafold_pdb(identifier, output_directory):\n",
    "    # Append '-model_v4' so that the URL becomes, for example:\n",
    "    # https://alphafold.ebi.ac.uk/files/AF-P09601-F1-model_v4.pdb\n",
    "    pdb_url = f\"{alphafold_download_base_url}{identifier}-model_v4.pdb\"\n",
    "    try:\n",
    "        response = requests.get(pdb_url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        pdb_file_path = os.path.join(output_directory, f\"{identifier}.pdb\")\n",
    "        with open(pdb_file_path, 'wb') as pdb_file:\n",
    "            pdb_file.write(response.content)\n",
    "\n",
    "        print(f\"Downloaded (AlphaFold): {identifier}.pdb\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download {identifier} from AlphaFold: {e}\")\n",
    "\n",
    "# Download AlphaFold PDB files (only for entries starting with \"AF-\")\n",
    "for identifier in df_receptor_hmox1['Identifier']:\n",
    "    if identifier.startswith(\"AF-\"):\n",
    "        download_alphafold_pdb(identifier, alphafold_output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ligand: DF Experimental Structures (RCSB PDB)\n",
    "\n",
    "some notes after troubleshooting\n",
    "\n",
    "-do not ask requests from the website at once, queue the requests.\n",
    "\n",
    "-check the resolution. extract the data too.\n",
    "\n",
    "-do not create seperate rows for each chain ID but include them in one cell.\n",
    "\n",
    "-include the names of the files without availabla sructures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: asyncio in /Users/nusin/miniconda3/envs/vscode_env/lib/python3.10/site-packages (3.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: aiohttp in /Users/nusin/miniconda3/envs/vscode_env/lib/python3.10/site-packages (3.11.12)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/nusin/miniconda3/envs/vscode_env/lib/python3.10/site-packages (from aiohttp) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/nusin/miniconda3/envs/vscode_env/lib/python3.10/site-packages (from aiohttp) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/nusin/miniconda3/envs/vscode_env/lib/python3.10/site-packages (from aiohttp) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/nusin/miniconda3/envs/vscode_env/lib/python3.10/site-packages (from aiohttp) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/nusin/miniconda3/envs/vscode_env/lib/python3.10/site-packages (from aiohttp) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/nusin/miniconda3/envs/vscode_env/lib/python3.10/site-packages (from aiohttp) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/nusin/miniconda3/envs/vscode_env/lib/python3.10/site-packages (from aiohttp) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/nusin/miniconda3/envs/vscode_env/lib/python3.10/site-packages (from aiohttp) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/nusin/miniconda3/envs/vscode_env/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/nusin/miniconda3/envs/vscode_env/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp) (3.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openpyxl in /Users/nusin/miniconda3/envs/vscode_env/lib/python3.10/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /Users/nusin/miniconda3/envs/vscode_env/lib/python3.10/site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Processing P01040...\n",
      "Processing P07900...\n",
      "Processing P11021...\n",
      "Processing Q06830...\n",
      "Processing P60709...\n",
      "Processing P07355...\n",
      "Processing Q8N163...\n",
      "Processing Q9NX63...\n",
      "Processing P13073...\n",
      "Processing P21291...\n",
      "Empty response for accession Q9NX63. Skipping.\n",
      "Processing P68104...\n",
      "Empty response for accession P21291. Skipping.\n",
      "Processing P06733...\n",
      "Processing P21333...\n",
      "Processing P04406...\n",
      "Processing P04899...\n",
      "Processing Q92522...\n",
      "Processing P16402...\n",
      "Processing P16401...\n",
      "Processing Q16777...\n",
      "Processing Q7L7L0...\n",
      "Processing Q5QNW6...\n",
      "Processing P84243...\n",
      "Processing P68431...\n",
      "Processing Q71DI3...\n",
      "Processing P62805...\n",
      "Processing Q32P51...\n",
      "Empty response for accession Q32P51. Skipping.\n",
      "Processing P31943...\n",
      "Processing Q00839...\n",
      "Empty response for accession Q00839. Skipping.\n",
      "Processing Q5SSJ5...\n",
      "Processing P08238...\n",
      "Processing P54652...\n",
      "Processing P11142...\n",
      "Processing P05783...\n",
      "Processing Q14739...\n",
      "Processing O00182...\n",
      "Processing P02545...\n",
      "Empty response for accession P05783. Skipping.\n",
      "Processing Q9BQG0...\n",
      "Empty response for accession Q9BQG0. Skipping.\n",
      "Processing P35579...\n",
      "Processing P06748...\n",
      "Processing P35232...\n",
      "Processing Q99623...\n",
      "Processing P78527...\n",
      "Processing P60900...\n",
      "Processing P15153...\n",
      "Processing P04844...\n",
      "Processing Q9Y265...\n",
      "Processing Q9Y230...\n",
      "Processing Q9Y3Z3...\n",
      "Processing P62318...\n",
      "Processing P42167...\n",
      "Empty response for accession P42167. Skipping.\n",
      "Processing Q9BQE3...\n",
      "Processing P62987...\n",
      "Empty response for accession Q9BQE3. Skipping.\n",
      "Processing P08670...\n",
      "Processing P62258...\n",
      "Processing Q09666...\n",
      "Processing P38646...\n",
      "Error querying RCSB for P62318: \n",
      "Processing P29966...\n",
      "Processing Q96PK6...\n",
      "Processing P55735...\n",
      "Processing P59998...\n",
      "Processing P51572...\n",
      "Processing Q86VB7...\n",
      "Processing Q07065...\n",
      "Empty response for accession Q07065. Skipping.\n",
      "Processing Q15149...\n",
      "Processing Q9Y6N5...\n",
      "Error querying RCSB for P59998: \n",
      "Processing P21281...\n",
      "Processing P52907...\n",
      "Processing P40939...\n",
      "Processing P51659...\n",
      "Processing P14625...\n",
      "Processing Q96RQ9...\n",
      "Processing Q14847...\n",
      "Empty response for accession Q96RQ9. Skipping.\n",
      "Processing P10620...\n",
      "Processing P14780...\n",
      "Empty response for accession P10620. Skipping.\n",
      "Processing O14950...\n",
      "Processing Q9Y490...\n",
      "Empty response for accession O14950. Skipping.\n",
      "  Gene Symbol  Ensembl Gene ID Accession Pfam IDs Identifier Method  \\\n",
      "0        CSTA  ENSG00000121552    P01040  Pf00031       1CYU    NMR   \n",
      "1        CSTA  ENSG00000121552    P01040  Pf00031       1CYV    NMR   \n",
      "2        CSTA  ENSG00000121552    P01040  Pf00031       1DVC    NMR   \n",
      "3        CSTA  ENSG00000121552    P01040  Pf00031       1DVD    NMR   \n",
      "4        CSTA  ENSG00000121552    P01040  Pf00031       1GD3    NMR   \n",
      "\n",
      "  Resolution Chain Positions  Length  \n",
      "0        N/A     A      1-98      98  \n",
      "1        N/A     A      1-98      98  \n",
      "2        N/A     A      1-98      98  \n",
      "3        N/A     A      1-98      98  \n",
      "4        N/A     A      1-98      98  \n",
      "Saved ligand structures to /Users/nusin/Library/Mobile Documents/com~apple~CloudDocs/Desktop/IOV/3_Projects/PPI/1_Input_Proteins_pdbs/df_all_ligands.csv\n"
     ]
    }
   ],
   "source": [
    "%pip install asyncio\n",
    "%pip install aiohttp\n",
    "%pip install openpyxl\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# (Optional) Suppress openpyxl conditional formatting warning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"openpyxl\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 1. Load and clean ligand data from the Excel file\n",
    "# -----------------------------\n",
    "ligand_file_path = \"/Users/nusin/Library/Mobile Documents/com~apple~CloudDocs/Desktop/IOV/3_Projects/PPI/0_Proteins_of_Interest/list of 75 proteins of interest.xlsx\"\n",
    "ligand_df = pd.read_excel(ligand_file_path)\n",
    "ligand_df.columns = ligand_df.columns.str.strip()\n",
    "ligand_df['Accession'] = ligand_df['Accession'].str.replace(r'-1$', '', regex=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2. Define an async function to get the UniProt sequence length using the fasta endpoint\n",
    "# -----------------------------\n",
    "async def get_uniprot_sequence(accession, session):\n",
    "    uniprot_url = f\"https://www.uniprot.org/uniprot/{accession}.fasta\"\n",
    "    try:\n",
    "        async with session.get(uniprot_url, timeout=10) as response:\n",
    "            if response.status == 200:\n",
    "                fasta_data = await response.text()\n",
    "                # Skip the header (first line) and join the rest to get the full sequence\n",
    "                sequence = \"\".join(fasta_data.splitlines()[1:])\n",
    "                return len(sequence)\n",
    "            else:\n",
    "                print(f\"Failed to fetch UniProt FASTA data for {accession}, Status code: {response.status}\")\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching UniProt FASTA data for {accession}: {e}\")\n",
    "        return None\n",
    "\n",
    "# -----------------------------\n",
    "# (Optional) If you need the UniProt JSON data for other purposes, you can still use this function.\n",
    "# -----------------------------\n",
    "async def get_uniprot_json_data(accession, session):\n",
    "    url = f\"https://rest.uniprot.org/uniprotkb/{accession}?format=json\"\n",
    "    try:\n",
    "        async with session.get(url, timeout=10) as response:\n",
    "            if response.status == 200:\n",
    "                return await response.json()\n",
    "            else:\n",
    "                print(f\"Failed to fetch UniProt JSON data for {accession}, Status code: {response.status}\")\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching UniProt JSON data for {accession}: {e}\")\n",
    "        return None\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3. Define an async function to process one ligand\n",
    "# -----------------------------\n",
    "async def process_ligand(session, row):\n",
    "    results_list = []\n",
    "    gene_symbol = row[\"Gene Symbol\"]\n",
    "    ensembl_gene_id = row[\"Ensembl Gene ID\"]\n",
    "    accession = row[\"Accession\"]\n",
    "    pfam_ids = row[\"Pfam IDs\"]\n",
    "\n",
    "    print(f\"Processing {accession}...\")\n",
    "\n",
    "    # Get UniProt sequence length using the FASTA endpoint\n",
    "    seq_length = await get_uniprot_sequence(accession, session)\n",
    "    if seq_length is None:\n",
    "        print(f\"Skipping {accession} due to missing UniProt sequence.\")\n",
    "        # Even if sequence length is missing, create a row with N/A for identifier\n",
    "        results_list.append({\n",
    "            \"Gene Symbol\": gene_symbol,\n",
    "            \"Ensembl Gene ID\": ensembl_gene_id,\n",
    "            \"Accession\": accession,\n",
    "            \"Pfam IDs\": pfam_ids,\n",
    "            \"Identifier\": \"N/A\",\n",
    "            \"Method\": \"N/A\",\n",
    "            \"Resolution\": \"N/A\",\n",
    "            \"Chain\": \"N/A\",\n",
    "            \"Positions\": \"N/A\",\n",
    "            \"Length\": \"N/A\"\n",
    "        })\n",
    "        return results_list\n",
    "\n",
    "    # (Optional) Get UniProt JSON data if needed for other details\n",
    "    # uniprot_json = await get_uniprot_json_data(accession, session)\n",
    "    # [You can process uniprot_json here if needed]\n",
    "\n",
    "    # Build the JSON query for experimental structures (RCSB)\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"type\": \"group\",\n",
    "            \"logical_operator\": \"and\",\n",
    "            \"nodes\": [\n",
    "                {\n",
    "                    \"type\": \"terminal\",\n",
    "                    \"service\": \"text\",\n",
    "                    \"parameters\": {\n",
    "                        \"attribute\": \"rcsb_polymer_entity_container_identifiers.reference_sequence_identifiers.database_accession\",\n",
    "                        \"operator\": \"exact_match\",\n",
    "                        \"value\": accession\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"terminal\",\n",
    "                    \"service\": \"text\",\n",
    "                    \"parameters\": {\n",
    "                        \"attribute\": \"rcsb_polymer_entity_container_identifiers.reference_sequence_identifiers.database_name\",\n",
    "                        \"operator\": \"exact_match\",\n",
    "                        \"value\": \"UniProt\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"return_type\": \"entry\",\n",
    "        \"request_options\": {\"return_all_hits\": True}\n",
    "    }\n",
    "\n",
    "    rcsb_query_url = \"https://search.rcsb.org/rcsbsearch/v2/query\"\n",
    "    \n",
    "    try:\n",
    "        async with session.post(rcsb_query_url, json=query, timeout=10) as response:\n",
    "            text = await response.text()\n",
    "            if not text.strip():\n",
    "                print(f\"Empty response for accession {accession}. Skipping.\")\n",
    "                # Even if the response is empty, create a row with N/A for identifier\n",
    "                results_list.append({\n",
    "                    \"Gene Symbol\": gene_symbol,\n",
    "                    \"Ensembl Gene ID\": ensembl_gene_id,\n",
    "                    \"Accession\": accession,\n",
    "                    \"Pfam IDs\": pfam_ids,\n",
    "                    \"Identifier\": \"N/A\",\n",
    "                    \"Method\": \"N/A\",\n",
    "                    \"Resolution\": \"N/A\",\n",
    "                    \"Chain\": \"N/A\",\n",
    "                    \"Positions\": f\"1-{seq_length}\",\n",
    "                    \"Length\": seq_length\n",
    "                })\n",
    "                return results_list\n",
    "            result = await response.json()\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying RCSB for {accession}: {e}\")\n",
    "        # Even if there's an error querying, create a row with N/A for identifier\n",
    "        results_list.append({\n",
    "            \"Gene Symbol\": gene_symbol,\n",
    "            \"Ensembl Gene ID\": ensembl_gene_id,\n",
    "            \"Accession\": accession,\n",
    "            \"Pfam IDs\": pfam_ids,\n",
    "            \"Identifier\": \"N/A\",\n",
    "            \"Method\": \"N/A\",\n",
    "            \"Resolution\": \"N/A\",\n",
    "            \"Chain\": \"N/A\",\n",
    "            \"Positions\": f\"1-{seq_length}\",\n",
    "            \"Length\": seq_length\n",
    "        })\n",
    "        return results_list\n",
    "\n",
    "    pdb_ids = [entry[\"identifier\"] for entry in result.get(\"result_set\", [])]\n",
    "    if not pdb_ids:\n",
    "        print(f\"No PDB IDs found for {accession}. Skipping.\")\n",
    "        # Even if no PDB IDs are found, create a row with N/A for identifier\n",
    "        results_list.append({\n",
    "            \"Gene Symbol\": gene_symbol,\n",
    "            \"Ensembl Gene ID\": ensembl_gene_id,\n",
    "            \"Accession\": accession,\n",
    "            \"Pfam IDs\": pfam_ids,\n",
    "            \"Identifier\": \"N/A\",\n",
    "            \"Method\": \"N/A\",\n",
    "            \"Resolution\": \"N/A\",\n",
    "            \"Chain\": \"N/A\",\n",
    "            \"Positions\": f\"1-{seq_length}\",\n",
    "            \"Length\": seq_length\n",
    "        })\n",
    "        return results_list\n",
    "\n",
    "    for pdb_id in pdb_ids:\n",
    "        pdb_url = f\"https://data.rcsb.org/rest/v1/core/entry/{pdb_id}\"\n",
    "        try:\n",
    "            async with session.get(pdb_url, timeout=10) as pdb_response:\n",
    "                pdb_data = await pdb_response.json()\n",
    "                method = pdb_data.get(\"rcsb_entry_info\", {}).get(\"experimental_method\", \"N/A\")\n",
    "                # Extract resolution using the \"resolution_combined\" field (as in the receptor code)\n",
    "                resolution_list = pdb_data.get(\"rcsb_entry_info\", {}).get(\"resolution_combined\", [\"N/A\"])\n",
    "                resolution = resolution_list[0]\n",
    "                if resolution != \"N/A\":\n",
    "                    resolution = f\"{resolution} Å\"\n",
    "\n",
    "                polymer_entities = pdb_data.get(\"rcsb_entry_container_identifiers\", {}).get(\"polymer_entity_ids\", [])\n",
    "                all_chains = []\n",
    "\n",
    "                # Process each polymer entity to accumulate chain identifiers\n",
    "                for entity_id in polymer_entities:\n",
    "                    entity_url = f\"https://data.rcsb.org/rest/v1/core/polymer_entity/{pdb_id}/{entity_id}\"\n",
    "                    try:\n",
    "                        async with session.get(entity_url, timeout=10) as entity_response:\n",
    "                            entity_data = await entity_response.json()\n",
    "                            chain_list = entity_data.get(\"rcsb_polymer_entity_container_identifiers\", {}).get(\"auth_asym_ids\", [])\n",
    "                            if chain_list:\n",
    "                                all_chains.extend(chain_list)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error fetching polymer entity {entity_id} for {pdb_id}: {e}\")\n",
    "                        continue\n",
    "\n",
    "                # Combine all chains into a single string, separated by '/'\n",
    "                chain = \"/\".join(all_chains) if all_chains else \"N/A\"\n",
    "\n",
    "                # Check if the protein entry already exists in results_list\n",
    "                existing_entry = next((res for res in results_list if res[\"Identifier\"] == pdb_id), None)\n",
    "                if existing_entry:\n",
    "                    existing_entry[\"Chain\"] += f\"/{chain}\" if chain != \"N/A\" else \"\"\n",
    "                else:\n",
    "                    results_list.append({\n",
    "                        \"Gene Symbol\": gene_symbol,\n",
    "                        \"Ensembl Gene ID\": ensembl_gene_id,\n",
    "                        \"Accession\": accession,\n",
    "                        \"Pfam IDs\": pfam_ids,\n",
    "                        \"Identifier\": pdb_id,\n",
    "                        \"Method\": method,\n",
    "                        \"Resolution\": resolution,\n",
    "                        \"Chain\": chain,\n",
    "                        \"Positions\": f\"1-{seq_length}\",\n",
    "                        \"Length\": seq_length\n",
    "                    })\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching PDB entry details for {pdb_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return results_list\n",
    "\n",
    "# -----------------------------\n",
    "# Wrap process_ligand with a semaphore to limit concurrent tasks\n",
    "# -----------------------------\n",
    "async def sem_process_ligand(semaphore, session, row):\n",
    "    async with semaphore:\n",
    "        return await process_ligand(session, row)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 4. Process all ligands concurrently (limit to 10 concurrent tasks)\n",
    "# -----------------------------\n",
    "async def fetch_ligand_structures():\n",
    "    all_results = []\n",
    "    semaphore = asyncio.Semaphore(10)  # Limit concurrent tasks\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for idx, row in ligand_df.iterrows():\n",
    "            tasks.append(sem_process_ligand(semaphore, session, row))\n",
    "        ligands_results = await asyncio.gather(*tasks)\n",
    "        for result in ligands_results:\n",
    "            all_results.extend(result)\n",
    "    return all_results\n",
    "\n",
    "# -----------------------------\n",
    "# Step 5. Main async function to get data and save results\n",
    "# -----------------------------\n",
    "async def main():\n",
    "    ligand_results = await fetch_ligand_structures()\n",
    "    df_ligand_structures = pd.DataFrame(ligand_results)\n",
    "    print(df_ligand_structures.head())\n",
    "    save_path = \"/Users/nusin/Library/Mobile Documents/com~apple~CloudDocs/Desktop/IOV/3_Projects/PPI/1_Input_Proteins_pdbs/df_all_ligands.csv\"\n",
    "    df_ligand_structures.to_csv(save_path, index=False)\n",
    "    print(f\"Saved ligand structures to {save_path}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Run the async main function (e.g., in Jupyter, use await main())\n",
    "# -----------------------------\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ligand: Filter Experimental Structures (RCSB PDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data:\n",
      "  Gene Symbol  Ensembl Gene ID Accession          Pfam IDs Identifier Method  \\\n",
      "0      LGALS9  ENSG00000168961    O00182           Pf00337       3LSE  X-ray   \n",
      "1      LGALS9  ENSG00000168961    O00182           Pf00337       3NV2  X-ray   \n",
      "2      MYL12B  ENSG00000118680    O14950  Pf08976, Pf13499        N/A    N/A   \n",
      "3        CSTA  ENSG00000121552    P01040           Pf00031       8GT0  X-ray   \n",
      "4        CSTA  ENSG00000121552    P01040           Pf00031       8GT7  X-ray   \n",
      "\n",
      "  Resolution        Chain Positions  Length Position Length  \n",
      "0     2.69 Å            A     1-355     355           355.0  \n",
      "1     2.34 Å            A     1-355     355           355.0  \n",
      "2        N/A          N/A     1-172     172             N/A  \n",
      "3     3.28 Å    A/C/E/B/D      1-98      98            98.0  \n",
      "4     3.28 Å  A/C/B/D/E/F      1-98      98            98.0  \n",
      "Saved filtered ligand structures to /Users/nusin/Library/Mobile Documents/com~apple~CloudDocs/Desktop/IOV/3_Projects/PPI/1_Input_Proteins_pdbs/df_filtered_ligands.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to apply filters\n",
    "def filter_ligand_structures(ligand_df):\n",
    "    # Group by the \"Accession\" to handle duplicates and prioritize based on criteria\n",
    "    grouped = ligand_df.groupby(\"Accession\")\n",
    "\n",
    "    filtered_results = []\n",
    "    for accession, group in grouped:\n",
    "        if len(group) <= 2:\n",
    "            # If there are one or two rows, keep all of them\n",
    "            filtered_results.append(group)\n",
    "        else:\n",
    "            # If there are more than 2 rows, prioritize by \"Positions\" length\n",
    "            group[\"Position Length\"] = group[\"Positions\"].str.split('-').str[1].astype(int)\n",
    "            max_position_length = group[\"Position Length\"].max()\n",
    "\n",
    "            # Filter out rows with the maximum position length\n",
    "            max_position_rows = group[group[\"Position Length\"] == max_position_length]\n",
    "\n",
    "            if len(max_position_rows) > 2:\n",
    "                # If there are still more than 2 rows with the same longest \"Positions\", prioritize by \"Resolution\"\n",
    "                max_position_rows = max_position_rows.sort_values(by=\"Resolution\", ascending=False)\n",
    "\n",
    "            # Append exactly 2 entries, even if there are more after filtering\n",
    "            filtered_results.append(max_position_rows.head(2))  # Only take the top 2\n",
    "\n",
    "    # Concatenate all filtered results and reset index\n",
    "    final_filtered_df = pd.concat(filtered_results).reset_index(drop=True)\n",
    "\n",
    "    # Fill missing values with \"N/A\"\n",
    "    final_filtered_df = final_filtered_df.fillna('N/A')\n",
    "\n",
    "    return final_filtered_df\n",
    "\n",
    "# -----------------------------\n",
    "# Apply filters and save the results\n",
    "# -----------------------------\n",
    "def apply_filters_and_save():\n",
    "    # Load the data from the specified CSV file\n",
    "    file_path = \"/Users/nusin/Library/Mobile Documents/com~apple~CloudDocs/Desktop/IOV/3_Projects/PPI/1_Input_Proteins_pdbs/df_all_ligands.csv\"\n",
    "    df_ligand_structures = pd.read_csv(file_path)\n",
    "    \n",
    "    filtered_df = filter_ligand_structures(df_ligand_structures)\n",
    "    print(f\"Filtered data:\\n{filtered_df.head()}\")\n",
    "    \n",
    "    # Save the filtered data to a new CSV file\n",
    "    save_path = \"/Users/nusin/Library/Mobile Documents/com~apple~CloudDocs/Desktop/IOV/3_Projects/PPI/1_Input_Proteins_pdbs/df_filtered_ligands.csv\"\n",
    "    filtered_df.to_csv(save_path, index=False)\n",
    "    print(f\"Saved filtered ligand structures to {save_path}\")\n",
    "\n",
    "# Apply the filters and save the results\n",
    "apply_filters_and_save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ligand: Merge DF Experimental and Alphafold (RCSB PDB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame saved to: /Users/nusin/Library/Mobile Documents/com~apple~CloudDocs/Desktop/IOV/3_Projects/PPI/1_Input_Proteins_pdbs/df_merged_ligands.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Read the CSV with experimental (real structure) data ---\n",
    "exp_csv_path = \"/Users/nusin/Library/Mobile Documents/com~apple~CloudDocs/Desktop/IOV/3_Projects/PPI/1_Input_Proteins_pdbs/df_filtered_ligands.csv\"\n",
    "exp_df = pd.read_csv(exp_csv_path)\n",
    "\n",
    "# --- Step 2: Create a DataFrame with AlphaFold-predicted structure rows ---\n",
    "# For each unique accession, check if the AlphaFold file exists.\n",
    "unique_accessions = exp_df['Accession'].unique()\n",
    "alphafold_rows = []\n",
    "\n",
    "for accession in unique_accessions:\n",
    "    # Retrieve common info from one sample row for this accession\n",
    "    sample_row = exp_df[exp_df['Accession'] == accession].iloc[0]\n",
    "    \n",
    "    # Construct the AlphaFold identifier and URL\n",
    "    af_id = f\"AF-{accession}-F1\"\n",
    "    af_url = f\"https://alphafold.ebi.ac.uk/files/{af_id}-model_v4.pdb\"\n",
    "    \n",
    "    # Check if the AlphaFold file exists using a HEAD request.\n",
    "    try:\n",
    "        response = requests.head(af_url, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            method = \"Predicted\"\n",
    "            identifier = af_id\n",
    "        else:\n",
    "            method = \"No Predicted Structure\"\n",
    "            identifier = \"No Predicted Structure\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking AlphaFold for {accession}: {e}\")\n",
    "        method = \"No Predicted Structure\"\n",
    "        identifier = \"No Predicted Structure\"\n",
    "    \n",
    "    # Use the 'Length' (if available) to form the Positions string.\n",
    "    length = sample_row.get(\"Length\", \"\")\n",
    "    positions = f\"1-{length}\" if pd.notnull(length) and length != \"\" else \"\"\n",
    "    \n",
    "    alphafold_rows.append({\n",
    "        \"Gene Symbol\": sample_row[\"Gene Symbol\"],\n",
    "        \"Ensembl Gene ID\": sample_row[\"Ensembl Gene ID\"],\n",
    "        \"Accession\": accession,\n",
    "        \"Pfam IDs\": sample_row[\"Pfam IDs\"],\n",
    "        \"Identifier\": identifier,\n",
    "        \"Method\": method,\n",
    "        \"Resolution\": \"\",\n",
    "        \"Chain\": \"\",\n",
    "        \"Positions\": positions,\n",
    "        \"Length\": length\n",
    "    })\n",
    "\n",
    "alphafold_df = pd.DataFrame(alphafold_rows)\n",
    "\n",
    "# --- Step 3: Merge the experimental and AlphaFold DataFrames ---\n",
    "merged_df = pd.concat([exp_df, alphafold_df], ignore_index=True)\n",
    "\n",
    "# Sort the merged DataFrame by Accession (and optionally by Identifier)\n",
    "merged_df = merged_df.sort_values(by=[\"Accession\", \"Identifier\"])\n",
    "\n",
    "# --- Step 4: Fill missing values with \"N/A\" ---\n",
    "merged_df = merged_df.fillna('N/A')\n",
    "\n",
    "# --- Step 5: Save the merged DataFrame to a new CSV ---\n",
    "merged_csv_path = \"/Users/nusin/Library/Mobile Documents/com~apple~CloudDocs/Desktop/IOV/3_Projects/PPI/1_Input_Proteins_pdbs/df_merged_ligands.csv\"\n",
    "merged_df.to_csv(merged_csv_path, index=False)\n",
    "\n",
    "print(\"Merged DataFrame saved to:\", merged_csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ligand: Download Structures\n",
    "\n",
    "*now to download the structures as pdb files*\n",
    "\n",
    "For experimental data I am using: https://files.rcsb.org/download\n",
    "\n",
    "For alphafold strcutures I am using: https://alphafold.ebi.ac.uk/files\n",
    "\n",
    "Edit the csv, to show if it is downloaded: df_merged_ligands.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded (RCSB): 3LSE.pdb\n",
      "Downloaded (RCSB): 3NV2.pdb\n",
      "Downloaded (AlphaFold): AF-O00182-F1.pdb\n",
      "Downloaded (AlphaFold): AF-O14950-F1.pdb\n",
      "Downloaded (RCSB): 8GT0.pdb\n",
      "Downloaded (RCSB): 8GT7.pdb\n",
      "Downloaded (AlphaFold): AF-P01040-F1.pdb\n",
      "Downloaded (RCSB): 2YPT.pdb\n",
      "Downloaded (RCSB): 7D9N.pdb\n",
      "Downloaded (AlphaFold): AF-P02545-F1.pdb\n",
      "Downloaded (RCSB): 3GPD.pdb\n",
      "Downloaded (RCSB): 8DNS.pdb\n",
      "Downloaded (AlphaFold): AF-P04406-F1.pdb\n",
      "Downloaded (RCSB): 8B6L.pdb\n",
      "Downloaded (RCSB): 8PN9.pdb\n",
      "Downloaded (AlphaFold): AF-P04844-F1.pdb\n",
      "Downloaded (RCSB): 6D9H.pdb\n",
      "Failed to download 8Y45 from RCSB: 404 Client Error: Not Found for url: https://files.rcsb.org/download/8Y45.pdb\n",
      "Downloaded (AlphaFold): AF-P04899-F1.pdb\n",
      "Downloaded (AlphaFold): AF-P05783-F1.pdb\n",
      "Downloaded (RCSB): 5LAX.pdb\n",
      "Downloaded (RCSB): 8TRL.pdb\n",
      "Downloaded (AlphaFold): AF-P06733-F1.pdb\n",
      "Downloaded (RCSB): 8AH2.pdb\n",
      "Downloaded (RCSB): 8AS5.pdb\n",
      "Downloaded (AlphaFold): AF-P06748-F1.pdb\n",
      "Downloaded (RCSB): 4DRW.pdb\n",
      "Downloaded (RCSB): 5LQ2.pdb\n",
      "Downloaded (AlphaFold): AF-P07355-F1.pdb\n",
      "Downloaded (RCSB): 7KW7.pdb\n",
      "Downloaded (RCSB): 7RY1.pdb\n",
      "Downloaded (AlphaFold): AF-P07900-F1.pdb\n",
      "Downloaded (RCSB): 5FWL.pdb\n",
      "Downloaded (RCSB): 5FWM.pdb\n",
      "Downloaded (AlphaFold): AF-P08238-F1.pdb\n",
      "Downloaded (RCSB): 3UF1.pdb\n",
      "Failed to download 8RVE from RCSB: 404 Client Error: Not Found for url: https://files.rcsb.org/download/8RVE.pdb\n",
      "Downloaded (AlphaFold): AF-P08670-F1.pdb\n",
      "Downloaded (AlphaFold): AF-P10620-F1.pdb\n",
      "Downloaded (RCSB): 5E84.pdb\n",
      "Downloaded (RCSB): 5YPF.pdb\n",
      "Downloaded (AlphaFold): AF-P11021-F1.pdb\n",
      "Downloaded (RCSB): 4KBQ.pdb\n",
      "Downloaded (RCSB): 5AQQ.pdb\n",
      "Downloaded (AlphaFold): AF-P11142-F1.pdb\n",
      "Downloaded (RCSB): 5Z62.pdb\n",
      "Downloaded (AlphaFold): AF-P13073-F1.pdb\n",
      "Downloaded (RCSB): 4NH9.pdb\n",
      "Downloaded (RCSB): 7ULL.pdb\n",
      "Downloaded (AlphaFold): AF-P14625-F1.pdb\n",
      "Downloaded (RCSB): 4H2E.pdb\n",
      "Downloaded (RCSB): 5TH9.pdb\n",
      "Downloaded (AlphaFold): AF-P14780-F1.pdb\n",
      "Downloaded (RCSB): 1DS6.pdb\n",
      "Downloaded (RCSB): 2W2X.pdb\n",
      "Downloaded (AlphaFold): AF-P15153-F1.pdb\n",
      "Downloaded (RCSB): 2RHI.pdb\n",
      "Downloaded (AlphaFold): AF-P16401-F1.pdb\n",
      "Downloaded (RCSB): 7XX5.pdb\n",
      "Downloaded (AlphaFold): AF-P16402-F1.pdb\n",
      "Downloaded (RCSB): 6WM4.pdb\n",
      "Failed to download 7UNF from RCSB: 404 Client Error: Not Found for url: https://files.rcsb.org/download/7UNF.pdb\n",
      "Downloaded (AlphaFold): AF-P21281-F1.pdb\n",
      "Downloaded (AlphaFold): AF-P21291-F1.pdb\n",
      "Downloaded (RCSB): 2WFN.pdb\n",
      "Downloaded (RCSB): 6D8C.pdb\n",
      "Downloaded (AlphaFold): AF-P21333-F1.pdb\n",
      "Downloaded (RCSB): 1IWQ.pdb\n",
      "Downloaded (AlphaFold): AF-P29966-F1.pdb\n",
      "Downloaded (RCSB): 6DHS.pdb\n",
      "Failed to download 7ZUG from RCSB: 404 Client Error: Not Found for url: https://files.rcsb.org/download/7ZUG.pdb\n",
      "Downloaded (AlphaFold): AF-P31943-F1.pdb\n",
      "Downloaded (RCSB): 8RRH.pdb\n",
      "Downloaded (AlphaFold): AF-P35232-F1.pdb\n",
      "Downloaded (RCSB): 3ZWH.pdb\n",
      "Downloaded (RCSB): 4ETO.pdb\n",
      "Downloaded (AlphaFold): AF-P35579-F1.pdb\n",
      "Downloaded (RCSB): 9BLT.pdb\n",
      "Downloaded (RCSB): 9BLU.pdb\n",
      "Downloaded (AlphaFold): AF-P38646-F1.pdb\n",
      "Downloaded (RCSB): 5ZQZ.pdb\n",
      "Downloaded (RCSB): 5ZRV.pdb\n",
      "Downloaded (AlphaFold): AF-P40939-F1.pdb\n",
      "Downloaded (AlphaFold): AF-P42167-F1.pdb\n",
      "Downloaded (RCSB): 4JZL.pdb\n",
      "Downloaded (RCSB): 8XWX.pdb\n",
      "Downloaded (AlphaFold): AF-P51572-F1.pdb\n",
      "Downloaded (RCSB): 1S9C.pdb\n",
      "Downloaded (RCSB): 8AF2.pdb\n",
      "Downloaded (AlphaFold): AF-P51659-F1.pdb\n",
      "Downloaded (RCSB): 7T5Q.pdb\n",
      "Downloaded (RCSB): 8F8Q.pdb\n",
      "Downloaded (AlphaFold): AF-P52907-F1.pdb\n",
      "Downloaded (RCSB): 5FPD.pdb\n",
      "Downloaded (RCSB): 5FPE.pdb\n",
      "Downloaded (AlphaFold): AF-P54652-F1.pdb\n",
      "Failed to download 7PEQ from RCSB: 404 Client Error: Not Found for url: https://files.rcsb.org/download/7PEQ.pdb\n",
      "Failed to download 7R5J from RCSB: 404 Client Error: Not Found for url: https://files.rcsb.org/download/7R5J.pdb\n",
      "Downloaded (AlphaFold): AF-P55735-F1.pdb\n",
      "Downloaded (AlphaFold): AF-P59998-F1.pdb\n",
      "Failed to download 8VRK from RCSB: 404 Client Error: Not Found for url: https://files.rcsb.org/download/8VRK.pdb\n",
      "Failed to download 8XVG from RCSB: 404 Client Error: Not Found for url: https://files.rcsb.org/download/8XVG.pdb\n",
      "Downloaded (AlphaFold): AF-P60709-F1.pdb\n",
      "Downloaded (RCSB): 5T0I.pdb\n",
      "Downloaded (RCSB): 5T0J.pdb\n",
      "Downloaded (AlphaFold): AF-P60900-F1.pdb\n",
      "Downloaded (RCSB): 8DGM.pdb\n",
      "Downloaded (RCSB): 8Q1S.pdb\n",
      "Downloaded (AlphaFold): AF-P62258-F1.pdb\n",
      "Downloaded (AlphaFold): AF-P62318-F1.pdb\n",
      "Downloaded (RCSB): 6A5O.pdb\n",
      "Downloaded (RCSB): 7PFT.pdb\n",
      "Downloaded (AlphaFold): AF-P62805-F1.pdb\n",
      "Failed to download 4V6X from RCSB: 404 Client Error: Not Found for url: https://files.rcsb.org/download/4V6X.pdb\n",
      "Downloaded (RCSB): 5A5B.pdb\n",
      "Downloaded (AlphaFold): AF-P62987-F1.pdb\n",
      "Failed to download 6ZMO from RCSB: 404 Client Error: Not Found for url: https://files.rcsb.org/download/6ZMO.pdb\n",
      "Failed to download 8G6J from RCSB: 404 Client Error: Not Found for url: https://files.rcsb.org/download/8G6J.pdb\n",
      "Downloaded (AlphaFold): AF-P68104-F1.pdb\n",
      "Downloaded (RCSB): 6HKT.pdb\n",
      "Downloaded (RCSB): 7V9K.pdb\n",
      "Downloaded (AlphaFold): AF-P68431-F1.pdb\n",
      "Failed to download 8BOT from RCSB: 404 Client Error: Not Found for url: https://files.rcsb.org/download/8BOT.pdb\n",
      "Downloaded (RCSB): 8EZB.pdb\n",
      "Failed to download No Predicted Structure from RCSB: 400 Client Error: Bad Request for url: https://files.rcsb.org/download/No%20Predicted%20Structure.pdb\n",
      "Downloaded (RCSB): 6A5R.pdb\n",
      "Downloaded (AlphaFold): AF-P84243-F1.pdb\n",
      "Downloaded (AlphaFold): AF-Q00839-F1.pdb\n",
      "Downloaded (RCSB): 2RII.pdb\n",
      "Downloaded (RCSB): 7LJ1.pdb\n",
      "Downloaded (AlphaFold): AF-Q06830-F1.pdb\n",
      "Downloaded (AlphaFold): AF-Q07065-F1.pdb\n",
      "Downloaded (RCSB): 4FTG.pdb\n",
      "Downloaded (RCSB): 2DIG.pdb\n",
      "Downloaded (AlphaFold): AF-Q14739-F1.pdb\n",
      "Downloaded (RCSB): 3I35.pdb\n",
      "Downloaded (AlphaFold): AF-Q14847-F1.pdb\n",
      "Downloaded (RCSB): 4Q58.pdb\n",
      "Downloaded (RCSB): 5J1F.pdb\n",
      "Downloaded (RCSB): 6Y5E.pdb\n",
      "Downloaded (RCSB): 8EVJ.pdb\n",
      "Downloaded (AlphaFold): AF-Q16777-F1.pdb\n",
      "Downloaded (AlphaFold): AF-Q32P51-F1.pdb\n",
      "Downloaded (RCSB): 6MUO.pdb\n",
      "Downloaded (RCSB): 6MUP.pdb\n",
      "Downloaded (AlphaFold): AF-Q5QNW6-F1.pdb\n",
      "Downloaded (RCSB): 2RQP.pdb\n",
      "Downloaded (AlphaFold): AF-Q5SSJ5-F1.pdb\n",
      "Downloaded (RCSB): 7PFA.pdb\n",
      "Downloaded (AlphaFold): AF-Q71DI3-F1.pdb\n",
      "Downloaded (RCSB): 9FH9.pdb\n",
      "Downloaded (AlphaFold): AF-Q7L7L0-F1.pdb\n",
      "Downloaded (RCSB): 9FMU.pdb\n",
      "Downloaded (RCSB): 9FNO.pdb\n",
      "Downloaded (AlphaFold): AF-Q86VB7-F1.pdb\n",
      "Downloaded (RCSB): 8EZ6.pdb\n",
      "Downloaded (AlphaFold): AF-Q8N163-F1.pdb\n",
      "Downloaded (RCSB): 7K60.pdb\n",
      "Downloaded (RCSB): 7K63.pdb\n",
      "Downloaded (AlphaFold): AF-Q92522-F1.pdb\n",
      "Downloaded (RCSB): 2DNP.pdb\n",
      "Downloaded (AlphaFold): AF-Q96PK6-F1.pdb\n",
      "Downloaded (AlphaFold): AF-Q96RQ9-F1.pdb\n",
      "Downloaded (RCSB): 6IQE.pdb\n",
      "Downloaded (AlphaFold): AF-Q99623-F1.pdb\n",
      "Downloaded (AlphaFold): AF-Q9BQE3-F1.pdb\n",
      "Downloaded (AlphaFold): AF-Q9BQG0-F1.pdb\n",
      "Downloaded (AlphaFold): AF-Q9NX63-F1.pdb\n",
      "Failed to download 9C62 from RCSB: 404 Client Error: Not Found for url: https://files.rcsb.org/download/9C62.pdb\n",
      "Downloaded (AlphaFold): AF-Q9Y230-F1.pdb\n",
      "Downloaded (AlphaFold): AF-Q9Y265-F1.pdb\n",
      "Downloaded (RCSB): 5AO0.pdb\n",
      "Downloaded (RCSB): 5AO4.pdb\n",
      "Downloaded (AlphaFold): AF-Q9Y3Z3-F1.pdb\n",
      "Downloaded (RCSB): 1SYQ.pdb\n",
      "Downloaded (RCSB): 6R9T.pdb\n",
      "Downloaded (AlphaFold): AF-Q9Y490-F1.pdb\n",
      "Downloaded (RCSB): 6MP5.pdb\n",
      "Downloaded (RCSB): 6OI5.pdb\n",
      "Downloaded (AlphaFold): AF-Q9Y6N5-F1.pdb\n",
      "\n",
      "Files that failed to download:\n",
      "8Y45\n",
      "8RVE\n",
      "7UNF\n",
      "7ZUG\n",
      "7PEQ\n",
      "7R5J\n",
      "8VRK\n",
      "8XVG\n",
      "4V6X\n",
      "6ZMO\n",
      "8G6J\n",
      "8BOT\n",
      "No Predicted Structure\n",
      "9C62\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Paths\n",
    "df_ligand_path = '/Users/nusin/Library/Mobile Documents/com~apple~CloudDocs/Desktop/IOV/3_Projects/PPI/1_Input_Proteins_pdbs/df_merged_ligands.csv'\n",
    "\n",
    "# Output directories for ligand PDB files\n",
    "rcsb_output_dir = '/Users/nusin/Library/Mobile Documents/com~apple~CloudDocs/Desktop/IOV/3_Projects/PPI/1_Input_Proteins_pdbs/ligand_pdbs/rcsb'\n",
    "alphafold_output_dir = '/Users/nusin/Library/Mobile Documents/com~apple~CloudDocs/Desktop/IOV/3_Projects/PPI/1_Input_Proteins_pdbs/ligand_pdbs/alphafold'\n",
    "\n",
    "# Create directories if they do not exist\n",
    "os.makedirs(rcsb_output_dir, exist_ok=True)\n",
    "os.makedirs(alphafold_output_dir, exist_ok=True)\n",
    "\n",
    "# Load the ligand DataFrame\n",
    "df_ligand = pd.read_csv(df_ligand_path)\n",
    "\n",
    "# Base URLs\n",
    "rcsb_download_base_url = \"https://files.rcsb.org/download/\"\n",
    "alphafold_download_base_url = \"https://alphafold.ebi.ac.uk/files/\"\n",
    "\n",
    "# Function to download PDB files from RCSB\n",
    "def download_rcsb_pdb(identifier, output_directory):\n",
    "    pdb_url = f\"{rcsb_download_base_url}{identifier}.pdb\"\n",
    "    try:\n",
    "        response = requests.get(pdb_url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        pdb_file_path = os.path.join(output_directory, f\"{identifier}.pdb\")\n",
    "        with open(pdb_file_path, 'wb') as pdb_file:\n",
    "            pdb_file.write(response.content)\n",
    "        msg = f\"Downloaded (RCSB): {identifier}.pdb\"\n",
    "        print(msg)\n",
    "        return True, msg\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        msg = f\"Failed to download {identifier} from RCSB: {e}\"\n",
    "        print(msg)\n",
    "        return False, msg\n",
    "\n",
    "# Function to download AlphaFold PDB files\n",
    "def download_alphafold_pdb(identifier, output_directory):\n",
    "    pdb_url = f\"{alphafold_download_base_url}{identifier}-model_v4.pdb\"\n",
    "    try:\n",
    "        response = requests.get(pdb_url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        pdb_file_path = os.path.join(output_directory, f\"{identifier}.pdb\")\n",
    "        with open(pdb_file_path, 'wb') as pdb_file:\n",
    "            pdb_file.write(response.content)\n",
    "        msg = f\"Downloaded (AlphaFold): {identifier}.pdb\"\n",
    "        print(msg)\n",
    "        return True, msg\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        msg = f\"Failed to download {identifier} from AlphaFold: {e}\"\n",
    "        print(msg)\n",
    "        return False, msg\n",
    "\n",
    "# Download PDB files and record the results\n",
    "download_results = []\n",
    "failed_downloads = []  # To store failed download identifiers\n",
    "\n",
    "# Iterate over all unique identifiers in the DataFrame\n",
    "for identifier in df_ligand['Identifier'].dropna().unique():\n",
    "    if identifier.startswith(\"AF-\"):\n",
    "        success, message = download_alphafold_pdb(identifier, alphafold_output_dir)\n",
    "    else:\n",
    "        success, message = download_rcsb_pdb(identifier, rcsb_output_dir)\n",
    "    \n",
    "    # Mark which files failed\n",
    "    if not success:\n",
    "        failed_downloads.append(identifier)\n",
    "    \n",
    "    download_results.append((identifier, success, message))\n",
    "\n",
    "# Ensure N/A rows are included and marked correctly\n",
    "df_ligand['downloads'] = df_ligand.apply(\n",
    "    lambda row: 'no' if pd.isna(row['Identifier']) or row['Identifier'] in failed_downloads else 'yes', axis=1\n",
    ")\n",
    "\n",
    "# Save the updated DataFrame, ensuring that N/A rows are maintained\n",
    "df_ligand_path = \"/Users/nusin/Library/Mobile Documents/com~apple~CloudDocs/Desktop/IOV/3_Projects/PPI/1_Input_Proteins_pdbs/df_downloaded_ligands.csv\"\n",
    "df_ligand.to_csv(df_ligand_path, index=False)\n",
    "\n",
    "# Print failed downloads list\n",
    "if failed_downloads:\n",
    "    print(\"\\nFiles that failed to download:\")\n",
    "    for failed_file in failed_downloads:\n",
    "        print(failed_file)\n",
    "else:\n",
    "    print(\"\\nAll files were downloaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
